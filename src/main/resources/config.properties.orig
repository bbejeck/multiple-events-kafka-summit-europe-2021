#Required for streams application
application.id=

#Topics
# You'll need to create these three topics in Confluent Cloud
avro.wrapped.topic=avro-events-wrapped
avro.topic=avro-events
proto.topic=proto-events
# different property names for the streams application
streams.input.topic.name=avro-events
streams.output.topic.name=output

# Required connection configs for Kafka producer, consumer, and admin
# Delete everything below this line and then run `cat stack-configs/java-service-account* >> config.properties`

bootstrap.servers={{ BROKER_ENDPOINT }}
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='{{ CLUSTER_API_KEY }}' password='{{ CLUSTER_API_SECRET }}';
sasl.mechanism=PLAIN

# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

# Required connection configs for Confluent Cloud Schema Registry
schema.registry.url=https://{{ SR_ENDPOINT }}
basic.auth.credentials.source=USER_INFO
schema.registry.basic.auth.user.info={{ SR_API_KEY }}:{{ SR_API_SECRET }}


